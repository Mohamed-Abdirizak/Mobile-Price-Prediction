# -*- coding: utf-8 -*-
"""Mobile Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OBdS1RZgXKBcWb1uR_9Siqto-C04WmTz

# Part 1: Loading the dataset and libraries
"""

import pandas as pd

data = pd.read_csv("train.csv")

data.head()

"""# Part 2: Data understanding

"""

data.columns

data.shape

data.price_range.value_counts()

# 0(low cost), 1(medium cost), 2(high cost) and 3(very high cost).

"""## deleting uneeded variables

"""

data.head()

#### all the variables we need.................. cause midkasto wuxuu saameen kuleeyahay target varaiblkeena

from google.colab import drive
drive.mount('/content/drive')

"""# Part 3: Solving Missing Values

"""

data.head()

data.isnull().sum()

"""NO Missing values

# Part 4: Data Visualizaiton
"""

data.columns

"""## bar Chart : wifi"""

import matplotlib.pyplot as plt
import locale

# Set the locale to use commas for thousands separator
locale.setlocale(locale.LC_ALL, '')

# Calculate the count of each phishing category
phishing_counts = data['wifi'].value_counts()

# Sort the values in descending order
phishing_counts = phishing_counts.sort_values(ascending=False)

# Set the figure size
plt.figure(figsize=(8, 6))

# Create bar plot with the highest value labeled as "1st," the second-highest as "2nd," and so on
bar_plot = plt.bar(range(len(phishing_counts)), phishing_counts.values, color='skyblue')

# Add labels and title with increased font size
plt.xlabel('Rank', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.title('Number of phones that have a wifi', fontsize=14)

# Add count values on top of each bar with the ranking label
for i, count in enumerate(phishing_counts.values):
    formatted_count = locale.format_string('%d', count, grouping=True)  # Format count with commas
    plt.text(i, count, f'{i+1}st:\n{formatted_count}', ha='center', va='bottom', fontsize=10)

# Add extra space at the top of the plot
plt.ylim(top=max(phishing_counts.values) * 1.1)

# Add gridlines
plt.grid(axis='y', linestyle='--')

# Add legend
# plt.legend(['Count'], loc='upper right')

# Remove x-axis tick labels
plt.xticks([])

# Show the plot
plt.show()

!pip install squarify

"""## Pie Chart: number of mobile that have a 4g+"""

import matplotlib.pyplot as plt

# Assuming 'data' is your dataset with the variable containing 0s and 1s
# Count the occurrences of each value
value_counts = data['four_g'].value_counts()

# Create a pie chart
plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')

# Add title
plt.title('how many phones can accept 4g')

# Display the plot
plt.show()

import matplotlib.pyplot as plt

# Assuming 'data' is your dataset with the variable containing 0s and 1s
# Count the occurrences of each value
value_counts = data['price_range'].value_counts()

# Create a pie chart
plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')

# Add title
plt.title('Price Range Values')

# Display the plot
plt.show()

import matplotlib.pyplot as plt

# Assuming 'data' is your dataset with the variable containing 0s and 1s
# Count the occurrences of each value
value_counts = data['blue'].value_counts()

colors = ['skyblue', 'lightcoral']


# Create a donut chart
plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', wedgeprops={'width': 0.5}, colors = colors)

# Add title
plt.title('Is the Phone accepts the Bluetooth')

# Display the plot
plt.show()

"""##"""



import matplotlib.pyplot as plt

# Assuming 'data' is your dataset with the variable containing 0s and 1s
# Count the occurrences of each value
value_counts = data['price_range'].value_counts()

# Create a pie chart
plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')

# Add title
plt.title('Pie Chart')

# Display the plot
plt.show()

data.head()

data.n_cores.value_counts()

data.ram.value_counts()

"""## Bar chart : number of phones that have a 3g+"""

import matplotlib.pyplot as plt

# Calculate the count of each price range category
three_g_counts = data['three_g'].value_counts()

# Create bar plot
plt.bar(three_g_counts.index, three_g_counts.values)

# Add labels and title
plt.xlabel('three_g')
plt.ylabel('Count')
plt.title('Accepts 3g+')
# i = 0
# # Add count values on top of each bar
# for i, count in enumerate(three_g_counts.values):
#     plt.text(i, count, str(count), ha='center', va='bottom')

# print(i)
# print(count)
# print(str(count))
# Display the plot
plt.show()

import matplotlib.pyplot as plt

# Calculate the count of each category
three_g_counts = data['three_g'].value_counts()

# Create bar plot
plt.bar(three_g_counts.index, three_g_counts.values)

# Add labels and title
plt.xlabel('three_g')
plt.ylabel('Count')
plt.title('Accepts 3G+')

# Add count values on top or below each bar
for i, count in enumerate(three_g_counts.values):
    if i == 0:
        plt.text(i, count, str(count), ha='center', va='top')  # Display count below the first bar
    else:
        plt.text(i, count, str(count), ha='center', va='bottom')  # Display count above other bars

# Display the plot
plt.show()

"""## Comparing two variables

### Bar Plot: 4g and wifi
"""

import numpy as np
import matplotlib.pyplot as plt

# Assuming 'data' is your dataset with two columns: 'blue' and 'dual_sim'
# Count the occurrences of each category in both columns
value_counts1 = data['four_g'].value_counts()
value_counts2 = data['three_g'].value_counts()

# Set the width of the bars
bar_width = 0.35

# Set the positions of the bars on the x-axis
x1 = np.arange(len(value_counts1))
x2 = [x + bar_width for x in x1]

# Create the side-by-side bar plotst
plt.bar(x1, value_counts1.values, width=bar_width, label='Four g')
plt.bar(x2, value_counts2.values, width=bar_width, label='Three g')

# Add labels and title
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Comparison of four 4g and wifi')
plt.xticks([r + bar_width/2 for r in range(len(value_counts1))], value_counts1.index)

# Display the legend
plt.legend()

# Display the plot
plt.show()

"""### Bar plot: 3g and 4g"""



import numpy as np
import matplotlib.pyplot as plt

# Assuming 'data' is your dataset with two columns: 'blue' and 'dual_sim'
# Count the occurrences of each category in both columns
value_counts1 = data['four_g'].value_counts()
value_counts2 = data['three_g'].value_counts()

# Set the width of the bars
bar_width = 0.35

# Set the positions of the bars on the x-axis
x1 = np.arange(len(value_counts1))
x2 = [x + bar_width for x in x1]

# Create the side-by-side bar plots
plt.bar(x1, value_counts1.values, width=bar_width, label='Four g')
plt.bar(x2, value_counts2.values, width=bar_width, label='three_g')

# Add labels and title
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Comparison of four 4g and three_g')
plt.xticks([r + bar_width/2 for r in range(len(value_counts1))], value_counts1.index)

# Display the legend
plt.legend()

# Display the plot
plt.show()

data.head()

"""## Bar Plot: touch_screen and wifi"""

import numpy as np
import matplotlib.pyplot as plt

# Assuming 'data' is your dataset with two columns: 'blue' and 'dual_sim'
# Count the occurrences of each category in both columns
value_counts1 = data['touch_screen'].value_counts()
value_counts2 = data['wifi'].value_counts()

# Set the width of the bars
bar_width = 0.35

# Set the positions of the bars on the x-axis
x1 = np.arange(len(value_counts1))
x2 = [x + bar_width for x in x1]

# Create the side-by-side bar plots
plt.bar(x1, value_counts1.values, width=bar_width, label='Touch screen')
plt.bar(x2, value_counts2.values, width=bar_width, label='wifi')

# Add labels and title
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Comparison of Number of cores and clock speed')
plt.xticks([r + bar_width/2 for r in range(len(value_counts1))], value_counts1.index)

# Display the legend
plt.legend()

# Display the plot
plt.show()

import matplotlib.pyplot as plt


# Create scatter plot
plt.scatter(data['ram'], data['price_range'])

# Add labels and title
plt.xlabel('ram')
plt.ylabel('price range')
plt.title('Scatter Plot')

# Display the plot
plt.show()

count = len(data[data['price_range'] == 0]['ram'])
print(count)

count = len(data[data['price_range'] == 1]['ram'])
print(count)

count = len(data[data['price_range'] ==2]['ram'])
print(count)

count = len(data[data['price_range'] == 3]['ram'])
print(count)

































"""# Part 5: Feature Engineering: Adding New Features

"""

# Create new features
data['total_camera_megapixels'] = data['fc'] + data['pc']  # Total megapixels of front and primary cameras
data['screen_area'] = data['sc_h'] * data['sc_w']  # Screen area in square units
data['memory_to_weight_ratio'] = data['int_memory'] / data['mobile_wt']  # Memory to weight ratio
data['screen_resolution'] = data['px_width'] * data['px_height']  # Screen resolution in pixels
# data['screen_resolution'] = data['px_width'].astype(str) + 'x' + data['px_height'].astype(str)

data['processor_speed'] = data['clock_speed'] * data['n_cores']  # Processor speed based on clock speed and number of cores

# Assuming your dataset is stored in a pandas DataFrame called 'df'
data['ram'] = data['ram'] / 1024
data.rename(columns={'ram': 'ram_GB'}, inplace=True)

# Network Compatibility:
# "0" for no network compatibility,
# "1" for 3G compatibility,
# "2" for 4G compatibility, and
# "3" for devices compatible with both 3G and 4G networks.
data['network_compatibility'] = data['three_g'] + data['four_g'] * 2

# Delete used columns
data.drop(['fc', 'pc', 'sc_h', 'sc_w', 'px_height', 'px_width', 'clock_speed', 'int_memory', 'mobile_wt', 'n_cores','three_g', 'four_g'], axis=1, inplace=True)



data.head()

data.shape

data.dtypes



















"""# Part 6: Encding the Categorical Varaibles

In my dataset, there is no categorical variables, all of the are numerical

# Part 7: splitting Datasets into train and test
"""

from sklearn.model_selection import train_test_split

# Assuming your dataset is stored in a pandas DataFrame called 'df'
X = data.drop('price_range', axis=1)  # Features (all columns except the target variable)
y = data['price_range']  # Target variable



# testData = pd.read_csv('test.csv')

# y = testData



# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Normalizing train and test

"""

from sklearn.preprocessing import StandardScaler

# Assuming you have already split your data into training and testing sets
# X_train, X_test, y_train, y_test

# Create an instance of the StandardScaler
scaler = StandardScaler()

# Apply the scaler to both the training and testing data
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)



import seaborn as sns
corrvar = data.corr()
plt.figure(figsize=(10, 8))  # Adjust the figure size as needed
sns.heatmap(corrvar, annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

"""# Part 8: Building Models: using different models

"""



"""## Model 1: Logistic Regression

"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Assuming you have your training data (X_train, y_train) and test data (X_test, y_test)

# Create and train the logistic regression model
lr = LogisticRegression()
lr.fit(X_train, y_train)



# ...........................................HOW MACHINE TRIANS THE DATA

predict_train_y = lr.predict(X_train)



# Calculate the evaluation scores
lr_accuracy_train_y = accuracy_score(y_train, predict_train_y) * 100
lr_f1_train_y = f1_score(y_train, predict_train_y, average='macro')* 100
lr_precision_train_y = precision_score(y_train, predict_train_y, average='macro')* 100
lr_recall_train_y = recall_score(y_train, predict_train_y, average='macro')* 100


# Add the Neural Network model results to the DataFrame
train_result = pd.DataFrame([['Logistic Regression Train', lr_accuracy_train_y, lr_f1_train_y, lr_precision_train_y, lr_recall_train_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall'])







#........................................... PREDICT TEST DATA........................................................
# Use the trained model to predict labels for the test data
pred_test_y = lr.predict(X_test)


# Calculate the evaluation scores
lr_accuracy_test_y = accuracy_score(y_test, pred_test_y)* 100
lr_f1_test_y = f1_score(y_test, pred_test_y, average='macro')* 100
lr_precision_test_y = precision_score(y_test, pred_test_y, average='macro')* 100
lr_recall_test_y = recall_score(y_test, pred_test_y, average='macro')* 100



# Add the Neural Network model results to the DataFrame
test_result = pd.DataFrame([['Logistic Regression Test', lr_accuracy_test_y, lr_f1_test_y, lr_precision_test_y, lr_recall_test_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall'])




# # Add the Neural Network model results to the DataFrame
# results = results.append(pd.DataFrame([['Decision Tree', dt_accuracy, dt_f1, dt_precision, dt_recall]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']),ignore_index = True)



# # Print the evaluation scores
# print("Accuracy:", lr_accuracy_test_y)
# print("F1 Score:", lr_f1_test_y)
# print("Precision:", lr_precision_test_y)
# print("Recall:", lr_recall_test_y)



# y_pred_train = lr.predict(X_train)
# lr_accuracy_train = accuracy_score(y_train, y_pred_train)

# lr_accuracy_train



"""## Model 2: Decision Trees

"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Assuming you have your training data (X_train, y_train) and test data (X_test, y_test)

# Create and train the decision tree classifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)



# ...........................................HOW MACHINE TRIANS THE DATA

predict_train_y = dt.predict(X_train)



# Calculate the evaluation scores
dt_accuracy_train_y = accuracy_score(y_train, predict_train_y)* 100
dt_f1_train_y = f1_score(y_train, predict_train_y, average='macro')* 100
dt_precision_train_y = precision_score(y_train, predict_train_y, average='macro')* 100
dt_recall_train_y = recall_score(y_train, predict_train_y, average='macro')* 100


# Add the Neural Network model results to the DataFrame
train_result = train_result.append(pd.DataFrame([['Decision Tree Train', dt_accuracy_train_y, dt_f1_train_y, dt_precision_train_y, dt_recall_train_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



# results = results.append(pd.DataFrame([['Decision Tree Test', dt_accuracy_test_y, dt_f1_test_y, dt_precision_test_y, dt_recall_test_y]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



#........................................... PREDICT TEST DATA........................................................
# Use the trained model to predict labels for the test data
pred_test_y =dt.predict(X_test)


# Calculate the evaluation scores
dt_accuracy_test_y = accuracy_score(y_test, pred_test_y)* 100
dt_f1_test_y = f1_score(y_test, pred_test_y, average='macro')* 100
dt_precision_test_y = precision_score(y_test, pred_test_y, average='macro')* 100
dt_recall_test_y = recall_score(y_test, pred_test_y, average='macro')* 100



# Add the Neural Network model results to the DataFrame
test_result = test_result.append(pd.DataFrame([['Decision Tree Test', dt_accuracy_test_y, dt_f1_test_y, dt_precision_test_y, dt_recall_test_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)


# # Add the Neural Network model results to the DataFrame
# results = results.append(pd.DataFrame([['Decision Tree', dt_accuracy, dt_f1, dt_precision, dt_recall]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']),ignore_index = True)



# Print the evaluation scores
# print("Accuracy:", lr_accuracy_test_y)
# print("F1 Score:", lr_f1_test_y)
# print("Precision:", lr_precision_test_y)
# print("Recall:", lr_recall_test_y)





# Use the trained model to predict labels for the test data
# y_pred = dt.predict(X_test)

# # Calculate the evaluation scores
# dt_accuracy = accuracy_score(y_test, y_pred)
# dt_f1 = f1_score(y_test, y_pred, average='macro')
# dt_precision = precision_score(y_test, y_pred, average='macro')
# dt_recall = recall_score(y_test, y_pred, average='macro')



# # Add the Neural Network model results to the DataFrame
# results = results.append(pd.DataFrame([['Decision Tree', dt_accuracy, dt_f1, dt_precision, dt_recall]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']),ignore_index = True)


# # Print the evaluation scores
# print("Accuracy:", dt_accuracy)
# print("F1 Score:", dt_f1)
# print("Precision:", dt_precision)
# print("Recall:", dt_recall)

"""## Model 3: Random Forests

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Assuming you have your training data (X_train, y_train) and test data (X_test, y_test)

# Create and train the Random Forest classifier
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)



# ...........................................HOW MACHINE TRIANS THE DATA

predict_train_y = rf.predict(X_train)



# Calculate the evaluation scores
rf_accuracy_train_y = accuracy_score(y_train, predict_train_y)* 100
rf_f1_train_y = f1_score(y_train, predict_train_y, average='macro')* 100
rf_precision_train_y = precision_score(y_train, predict_train_y, average='macro')* 100
rf_recall_train_y = recall_score(y_train, predict_train_y, average='macro')* 100


# Add the Neural Network model results to the DataFrame
train_result = train_result.append(pd.DataFrame([['Random Forest Train', rf_accuracy_train_y, rf_f1_train_y, rf_precision_train_y, rf_recall_train_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



# results = results.append(pd.DataFrame([['Decision Tree Test', dt_accuracy_test_y, dt_f1_test_y, dt_precision_test_y, dt_recall_test_y]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



#........................................... PREDICT TEST DATA........................................................
# Use the trained model to predict labels for the test data
pred_test_y =rf.predict(X_test)


# Calculate the evaluation scores
rf_accuracy_test_y = accuracy_score(y_test, pred_test_y)* 100
rf_f1_test_y = f1_score(y_test, pred_test_y, average='macro')* 100
rf_precision_test_y = precision_score(y_test, pred_test_y, average='macro')* 100
rf_recall_test_y = recall_score(y_test, pred_test_y, average='macro')* 100



# Add the Neural Network model results to the DataFrame
test_result = test_result.append(pd.DataFrame([['Random Forest Test', rf_accuracy_test_y, rf_f1_test_y, rf_precision_test_y, rf_recall_test_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)


# # Use the trained model to predict labels for the test data
# y_pred = rf.predict(X_test)

# # Calculate the evaluation scores
# rf_accuracy = accuracy_score(y_test, y_pred)
# rf_f1 = f1_score(y_test, y_pred, average='macro')
# rf_precision = precision_score(y_test, y_pred, average='macro')
# rf_recall = recall_score(y_test, y_pred, average='macro')



# # Add the Neural Network model results to the DataFrame
# results = results.append(pd.DataFrame([['Random Forest', rf_accuracy, rf_f1, rf_precision, rf_recall]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']),ignore_index = True)

# # Print the evaluation scores
# print("Accuracy:", rf_accuracy)
# print("F1 Score:", rf_f1)
# print("Precision:", rf_precision)
# print("Recall:", rf_recall)

"""## Model 4: Gradient Boosting Machines (GBMs)

"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Assuming you have your training data (X_train, y_train) and test data (X_test, y_test)

# Create and train the Gradient Boosting classifier
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)



# ...........................................HOW MACHINE TRIANS THE DATA

predict_train_y = gb.predict(X_train)



# Calculate the evaluation scores
gb_accuracy_train_y = accuracy_score(y_train, predict_train_y)* 100
gb_f1_train_y = f1_score(y_train, predict_train_y, average='macro')* 100
gb_precision_train_y = precision_score(y_train, predict_train_y, average='macro')* 100
gb_recall_train_y = recall_score(y_train, predict_train_y, average='macro')* 100


# Add the Neural Network model results to the DataFrame
train_result = train_result.append(pd.DataFrame([['Gboost Train', gb_accuracy_train_y, gb_f1_train_y, gb_precision_train_y, gb_recall_train_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



# results = results.append(pd.DataFrame([['Decision Tree Test', dt_accuracy_test_y, dt_f1_test_y, dt_precision_test_y, dt_recall_test_y]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



#........................................... PREDICT TEST DATA........................................................
# Use the trained model to predict labels for the test data
pred_test_y =gb.predict(X_test)


# Calculate the evaluation scores
gb_accuracy_test_y = accuracy_score(y_test, pred_test_y)* 100
gb_f1_test_y = f1_score(y_test, pred_test_y, average='macro')* 100
gb_precision_test_y = precision_score(y_test, pred_test_y, average='macro')* 100
gb_recall_test_y = recall_score(y_test, pred_test_y, average='macro')* 100



# Add the Neural Network model results to the DataFrame
test_result = test_result.append(pd.DataFrame([['Gboost Test', gb_accuracy_test_y, gb_f1_test_y, gb_precision_test_y, gb_recall_test_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)

# # Use the trained model to predict labels for the test data
# y_pred = gb.predict(X_test)

# # Calculate the evaluation scores
# gb_accuracy = accuracy_score(y_test, y_pred)
# gb_f1 = f1_score(y_test, y_pred, average='macro')
# gb_precision = precision_score(y_test, y_pred, average='macro')
# gb_recall = recall_score(y_test, y_pred, average='macro')



# # Add the Neural Network model results to the DataFrame
# results = results.append(pd.DataFrame([['Grdient Boosting', gb_accuracy, gb_f1, gb_precision, gb_recall]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']),ignore_index = True)

# # Print the evaluation scores
# print("Accuracy:", gb_accuracy)
# print("F1 Score:", gb_f1)
# print("Precision:", gb_precision)
# print("Recall:", gb_recall)

"""## Model 5: Support Vector Machines (SVMs)

"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Assuming you have your training data (X_train, y_train) and test data (X_test, y_test)

# Create and train the SVM classifier
svm = SVC()
svm.fit(X_train, y_train)





# ...........................................HOW MACHINE TRIANS THE DATA

predict_train_y =svm.predict(X_train)



# Calculate the evaluation scores
svm_accuracy_train_y = accuracy_score(y_train, predict_train_y)* 100
svm_f1_train_y = f1_score(y_train, predict_train_y, average='macro')* 100
svm_precision_train_y = precision_score(y_train, predict_train_y, average='macro')* 100
svm_recall_train_y = recall_score(y_train, predict_train_y, average='macro')* 100


# Add the Neural Network model results to the DataFrame
train_result = train_result.append(pd.DataFrame([['SVM Train', svm_accuracy_train_y, svm_f1_train_y, svm_precision_train_y, svm_recall_train_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



# results = results.append(pd.DataFrame([['Decision Tree Test', dt_accuracy_test_y, dt_f1_test_y, dt_precision_test_y, dt_recall_test_y]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



#........................................... PREDICT TEST DATA........................................................
# Use the trained model to predict labels for the test data
pred_test_y =svm.predict(X_test)


# Calculate the evaluation scores
svm_accuracy_test_y = accuracy_score(y_test, pred_test_y)* 100
svm_f1_test_y = f1_score(y_test, pred_test_y, average='macro')* 100
svm_precision_test_y = precision_score(y_test, pred_test_y, average='macro')* 100
svm_recall_test_y = recall_score(y_test, pred_test_y, average='macro')* 100



# Add the Neural Network model results to the DataFrame
test_result = test_result.append(pd.DataFrame([['SVM Test', svm_accuracy_test_y, svm_f1_test_y, svm_precision_test_y, svm_recall_test_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)







# # Use the trained model to predict labels for the test data
# y_pred = svm.predict(X_test)

# # Calculate the evaluation scores
# svm_accuracy = accuracy_score(y_test, y_pred)
# svm_f1 = f1_score(y_test, y_pred, average='macro')
# svm_precision = precision_score(y_test, y_pred, average='macro')
# svm_recall = recall_score(y_test, y_pred, average='macro')


# # Add the Neural Network model results to the DataFrame
# results = results.append(pd.DataFrame([['SVM', svm_accuracy, svm_f1, svm_precision, svm_recall]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']),ignore_index = True)



# # Print the evaluation scores
# print("Accuracy:", svm_accuracy)
# print("F1 Score:", svm_f1)
# print("Precision:", svm_precision)
# print("Recall:", svm_recall)

"""## Model 6: Naive Bayes

"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Assuming you have your training data (X_train, y_train) and test data (X_test, y_test)

# Create and train the Naive Bayes classifier
nb = GaussianNB()
nb.fit(X_train, y_train)



# ...........................................HOW MACHINE TRIANS THE DATA

predict_train_y =nb.predict(X_train)



# Calculate the evaluation scores
nb_accuracy_train_y = accuracy_score(y_train, predict_train_y)* 100
nb_f1_train_y = f1_score(y_train, predict_train_y, average='macro')* 100
svm_precision_train_y = precision_score(y_train, predict_train_y, average='macro')* 100
svm_recall_train_y = recall_score(y_train, predict_train_y, average='macro')* 100


# Add the Neural Network model results to the DataFrame
train_result = train_result.append(pd.DataFrame([['Naive Beys Train',nb_accuracy_train_y, nb_f1_train_y, svm_precision_train_y, svm_recall_train_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



# results = results.append(pd.DataFrame([['Decision Tree Test', dt_accuracy_test_y, dt_f1_test_y, dt_precision_test_y, dt_recall_test_y]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



#........................................... PREDICT TEST DATA........................................................
# Use the trained model to predict labels for the test data
pred_test_y =nb.predict(X_test)


# Calculate the evaluation scores
nb_accuracy_test_y = accuracy_score(y_test, pred_test_y)* 100
nb_f1_test_y = f1_score(y_test, pred_test_y, average='macro')* 100
nb_precision_test_y = precision_score(y_test, pred_test_y, average='macro')* 100
nb_recall_test_y = recall_score(y_test, pred_test_y, average='macro')* 100



# Add the Neural Network model results to the DataFrame
test_result = test_result.append(pd.DataFrame([['Naive Beys Test',nb_accuracy_test_y , nb_f1_test_y, nb_precision_test_y, nb_recall_test_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)






# # Use the trained model to predict labels for the test data
# y_pred = nb.predict(X_test)

# # Calculate the evaluation scores
# nb_accuracy = accuracy_score(y_test, y_pred)
# nb_f1 = f1_score(y_test, y_pred, average='macro')
# nb_precision = precision_score(y_test, y_pred, average='macro')
# nb_recall = recall_score(y_test, y_pred, average='macro')



# # Add the Neural Network model results to the DataFrame
# results = results.append(pd.DataFrame([['Naive Beyes', nb_accuracy, nb_f1, nb_precision, nb_recall]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']) ,ignore_index = True)

# # Print the evaluation scores
# print("Accuracy:", nb_accuracy)
# print("F1 Score:", nb_f1)
# print("Precision:", nb_precision)
# print("Recall:", nb_recall)



"""## Model 7: k-Nearest Neighbors (k-NN)

"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Assuming you have your training data (X_train, y_train) and test data (X_test, y_test)

# Create and train the KNN classifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)


# ...........................................HOW MACHINE TRIANS THE DATA

predict_train_y =knn.predict(X_train)



# Calculate the evaluation scores
knn_accuracy_train_y = accuracy_score(y_train, predict_train_y)* 100
knn_f1_train_y = f1_score(y_train, predict_train_y, average='macro')* 100
knn_precision_train_y = precision_score(y_train, predict_train_y, average='macro')* 100
knn_recall_train_y = recall_score(y_train, predict_train_y, average='macro')* 100


# Add the Neural Network model results to the DataFrame
train_result = train_result.append(pd.DataFrame([['KNN Train',knn_accuracy_train_y, knn_f1_train_y, knn_precision_train_y, knn_recall_train_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



# results = results.append(pd.DataFrame([['Decision Tree Test', dt_accuracy_test_y, dt_f1_test_y, dt_precision_test_y, dt_recall_test_y]],
#                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)



#........................................... PREDICT TEST DATA........................................................
# Use the trained model to predict labels for the test data
pred_test_y =knn.predict(X_test)


# Calculate the evaluation scores
knn_accuracy_test_y = accuracy_score(y_test, pred_test_y)* 100
knn_f1_test_y = f1_score(y_test, pred_test_y, average='macro')* 100
knn_precision_test_y = precision_score(y_test, pred_test_y, average='macro')* 100
knn_recall_test_y = recall_score(y_test, pred_test_y, average='macro')* 100



# Add the Neural Network model results to the DataFrame
test_result = test_result.append(pd.DataFrame([['KNN Test',knn_accuracy_test_y , knn_f1_test_y, knn_precision_test_y, knn_recall_test_y]],
                                      columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)




# # Use the trained model to predict labels for the test data
# y_pred = knn.predict(X_test)

# # Calculate the evaluation scores
# knn_accuracy = accuracy_score(y_test, y_pred)
# knn_f1 = f1_score(y_test, y_pred, average='macro')
# knn_precision = precision_score(y_test, y_pred, average='macro')
# knn_recall = recall_score(y_test, y_pred, average='macro')

# # Add the Neural Network model results to the DataFrame
# # results = results.append(pd.DataFrame([['KNN', knn_accuracy, knn_f1, knn_precision, knn_recall]],
# #                                       columns=['Model', 'Accuracy', 'F1', 'Precision', 'Recall']), ignore_index = True)

# # Print the evaluation scores
# print("Accuracy:", knn_accuracy)
# print("F1 Score:", knn_f1)
# print("Precision:", knn_precision)
# print("Recall:", knn_recall)



"""# Part 9: choosing the best Model

## showing the trianing data as a dataframe
"""

train_result

"""## Displaying how data trained as a bar Graph"""

import matplotlib.pyplot as plt

models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gboost', 'SVM', 'Naive Bayes', 'KNN']
accuracy_train = [94.0625, 100.0000, 100.0000, 99.6875, 96.6250, 80.3750, 71.6250]

# Sort the models and accuracy scores together
sorted_data = sorted(zip(models, accuracy_train), key=lambda x: x[1], reverse=True)
sorted_models, sorted_accuracy = zip(*sorted_data)

# Set up the figure and axes
fig, ax = plt.subplots(figsize=(10, 6))

# Define custom colors for the bars
bar_colors = ['skyblue', 'lightgreen', 'lightcoral', 'orange', 'lightgray', 'lightpink', 'lightsalmon']

# Create a bar plot with ranking numbers and custom colors
bars = ax.bar(range(len(sorted_models)), sorted_accuracy, color=bar_colors)

# Customize the plot
ax.set_ylabel('Accuracy', fontsize=12)
ax.set_title('Accuracy Ranking of Different Models (Training Data)', fontsize=14, fontweight='bold')
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

# Add data labels on top of each bar with both percentage and ranking numbers
for i, bar in enumerate(bars):
    height = bar.get_height()
    ax.annotate(f'{sorted_accuracy[i]:.2f}%\n{i+1}st', xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3), textcoords='offset points', ha='center', va='bottom', fontsize=10)

# Set the x-axis tick labels to the sorted model names
ax.set_xticks(range(len(sorted_models)))
ax.set_xticklabels(sorted_models, rotation=45, ha='right')

# Add some space at the top of the plot
plt.ylim(top=max(sorted_accuracy) * 1.1)  # Adjust the 1.1 factor to increase or decrease the space

# Adjust the layout
plt.tight_layout()

# Display the plot
plt.show()

"""## showing the testing data Models as a dataframe


"""

test_result

"""## Displaying how data testing as a bar graph"""

import matplotlib.pyplot as plt

models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gboost', 'SVM', 'Naive Bayes', 'KNN']
accuracy = [92.25, 83.50, 88.50, 90.00, 86.50, 79.25, 56.00]

# Sort the models and accuracy scores together
sorted_data = sorted(zip(models, accuracy), key=lambda x: x[1], reverse=True)
sorted_models, sorted_accuracy = zip(*sorted_data)

# Set up the figure and axes
fig, ax = plt.subplots(figsize=(10, 6))

# Define custom colors for the bars
bar_colors = ['skyblue', 'lightgreen', 'lightcoral', 'orange', 'lightgray', 'lightpink', 'lightsalmon']

# Create a bar plot with ranking numbers and custom colors
bars = ax.bar(range(len(sorted_models)), sorted_accuracy, color=bar_colors)

# Customize the plot
ax.set_ylabel('Accuracy', fontsize=12)
ax.set_title('Accuracy Ranking of Different Models (Testing Data)', fontsize=14, fontweight='bold')
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

# Add data labels on top of each bar with both percentage and ranking numbers
for i, bar in enumerate(bars):
    height = bar.get_height()
    ax.annotate(f'{sorted_accuracy[i]:.2f}%\n{i+1}st', xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3), textcoords='offset points', ha='center', va='bottom', fontsize=10)

# Set the x-axis tick labels to the sorted model names
ax.set_xticks(range(len(sorted_models)))
ax.set_xticklabels(sorted_models, rotation=45, ha='right')

# Add some space at the top of the plot
plt.ylim(top=max(sorted_accuracy) * 1.1)  # Adjust the 1.1 factor to increase or decrease the space

# Adjust the layout
plt.tight_layout()

# Display the plot
plt.show()

"""The best model that fits to my dataset is Logistic Regresssion, Cause it has the Highest Value of Accuracy

# Part 9: Predicting all the models

## Confusion Matrix : Helps to tell how are truely predicted and how are wrongly predicted.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Example confusion matrix values for seven models
cm_values = [
    confusion_matrix(y_test, lr_prediction),
    confusion_matrix(y_test, dt_prediction),
    confusion_matrix(y_test, rf_prediction),
    confusion_matrix(y_test, gb_prediction),
    confusion_matrix(y_test, svm_prediction),
    confusion_matrix(y_test, nb_prediction),
    confusion_matrix(y_test, knn_prediction)
]

# Define class labels
class_labels = [0, 1, 2, 3]

# Define the titles for each model
model_titles = [
    'Confusion matrix of Logistic Regression',
    'Confusion matrix of Decision Tree',
    'Confusion matrix of Random Forest',
    'Confusion matrix of Gradient Boosting',
    'Confusion matrix of SVM',
    'Confusion matrix of Naive Bayes',
    'Confusion matrix of KNN'
]

# Create subplots for multiple graphs
fig, axes = plt.subplots(2, 4, figsize=(16, 8))

# Iterate over confusion matrices and corresponding subplots
for i, cm in enumerate(cm_values):
    # Calculate subplot position
    row = i // 4
    col = i % 4

    # Plot confusion matrix as a heatmap on the corresponding subplot
    ax = axes[row, col]
    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)

    # Customize plot
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=class_labels, yticklabels=class_labels,
           xlabel='Predicted label',
           ylabel='True label',
           title=model_titles[i])

    # Rotate the x-axis labels
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")

    # Loop over data dimensions and create text annotations
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]),
                    ha="center", va="center",
                    color="white" if cm[i, j] > np.max(cm) / 2 else "black")

    # Add colorbar
    cbar = ax.figure.colorbar(im, ax=ax)
    cbar.ax.set_ylabel("Counts", rotation=-90, va="bottom")

      # Add corrected and wrong predicted counts below the graph
    total_samples = np.sum(cm)
    correct_predictions = np.sum(np.diag(cm))
    wrong_predictions = total_samples - correct_predictions
    ax.text(0, -1.5, f'Corrected: {correct_predictions}/{total_samples} (TP+TN)\nWrong: {wrong_predictions}/{total_samples} (FP+FN)',
            ha="left", va="center", fontsize=10)

# Adjust spacing between subplots
plt.tight_layout()

# Show the plot
plt.show()

# saadaalin ku sameey 7daani X_test

# logisti regression : output will be only: price_prediction(0: low price, 1: normal price, 2: hight price, 3: high price)
lr_prediction = lr.predict(X_test)
# decision tree
dt_prediction = dt.predict(X_test)
# random forest
rf_prediction = rf.predict(X_test)
# gradient boosting
gb_prediction = gb.predict(X_test)
# svm
svm_prediction = svm.predict(X_test)
#  naive beys
nb_prediction = nb.predict(X_test)
#  knn
knn_prediction = knn.predict(X_test)

"""## Storing files on each predicted value and actual value"""

# ...........................................LOGISTIC REGRESSION.........................................
# Create a new DataFrame with the predicted labels and actual values
output_data = pd.DataFrame({'Predicted Lr': lr_prediction, 'Actual ': y_test})

# Specify the filename for the output Excel file
output_filename = 'predicted_actual_lr.xlsx'

# Save the DataFrame to Excel
output_data.to_excel(output_filename, index=False)

print(f"Predicted output saved to {output_filename}")

# ...........................................DECISION TREE.........................................
# Create a new DataFrame with the predicted labels and actual values
output_data = pd.DataFrame({'Predicted dt': dt_prediction, 'Actual ': y_test})

# Specify the filename for the output Excel file
output_filename = 'predicted_actual_dt.xlsx'

# Save the DataFrame to Excel
output_data.to_excel(output_filename, index=False)

print(f"Predicted output saved to {output_filename}")

# ...........................................DECISION TREE.........................................
# Create a new DataFrame with the predicted labels and actual values
output_data = pd.DataFrame({'Predicted rf': rf_prediction, 'Actual ': y_test})

# Specify the filename for the output Excel file
output_filename = 'predicted_actual_rf.xlsx'

# Save the DataFrame to Excel
output_data.to_excel(output_filename, index=False)

print(f"Predicted output saved to {output_filename}")

# ...........................................DECISION TREE.........................................
# Create a new DataFrame with the predicted labels and actual values
output_data = pd.DataFrame({'Predicted gb': gb_prediction, 'Actual ': y_test})

# Specify the filename for the output Excel file
output_filename = 'predicted_actual_gb.xlsx'

# Save the DataFrame to Excel
output_data.to_excel(output_filename, index=False)

print(f"Predicted output saved to {output_filename}")

# ...........................................DECISION TREE.........................................
# Create a new DataFrame with the predicted labels and actual values
output_data = pd.DataFrame({'Predicted svm': svm_prediction, 'Actual ': y_test})

# Specify the filename for the output Excel file
output_filename = 'predicted_actual_svm.xlsx'

# Save the DataFrame to Excel
output_data.to_excel(output_filename, index=False)

print(f"Predicted output saved to {output_filename}")

# ...........................................DECISION TREE.........................................
# Create a new DataFrame with the predicted labels and actual values
output_data = pd.DataFrame({'Predicted nb': nb_prediction, 'Actual ': y_test})

# Specify the filename for the output Excel file
output_filename = 'predicted_actual_nb.xlsx'

# Save the DataFrame to Excel
output_data.to_excel(output_filename, index=False)

print(f"Predicted output saved to {output_filename}")

# ...........................................DECISION TREE.........................................
# Create a new DataFrame with the predicted labels and actual values
output_data = pd.DataFrame({'Predicted knn': knn_prediction, 'Actual ': y_test})

# Specify the filename for the output Excel file
output_filename = 'predicted_actual_knn.xlsx'

# Save the DataFrame to Excel
output_data.to_excel(output_filename, index=False)

print(f"Predicted output saved to {output_filename}")



"""## read all the files, and check how are correctely predicted or not"""

#  .................................. SVM
#  ....................... HOW ARE TRULY PREDICTED AND HOW ARE WRONGLY PREDICTED......................

# Read the Excel file
df = pd.read_excel('predicted_actual_svm.xlsx')

# Initialize counters
correct_count = 0
wrong_count = 0

# Iterate through the rows in the DataFrame
for index, row in df.iterrows():
    predicted = row['Predicted svm']
    actual = row['Actual ']

    # Check if the predicted value matches the actual value
    if predicted == actual:
        correct_count += 1
    else:
        wrong_count += 1
corrected_svm = correct_count
wrong_svm = wrong_count
# Print the counts
print("Correctly predicted count:", correct_count)
print("Wrongly predicted count:", wrong_count)

#  .................................. DECISION TREE
#  ....................... HOW ARE TRULY PREDICTED AND HOW ARE WRONGLY PREDICTED......................

# Read the Excel file
df = pd.read_excel('predicted_actual_dt.xlsx')

# Initialize counters
correct_count = 0
wrong_count = 0

# Iterate through the rows in the DataFrame
for index, row in df.iterrows():
    predicted = row['Predicted dt']
    actual = row['Actual ']

    # Check if the predicted value matches the actual value
    if predicted == actual:
        correct_count += 1
    else:
        wrong_count += 1
corrected_dt = correct_count
wrong_dt = wrong_count
# Print the counts
print("Correctly predicted count:", correct_count)
print("Wrongly predicted count:", wrong_count)

#  .................................. GRADIENT BOOSTING
#  ....................... HOW ARE TRULY PREDICTED AND HOW ARE WRONGLY PREDICTED......................

# Read the Excel file
df = pd.read_excel('predicted_actual_gb.xlsx')

# Initialize counters
correct_count = 0
wrong_count = 0

# Iterate through the rows in the DataFrame
for index, row in df.iterrows():
    predicted = row['Predicted gb']
    actual = row['Actual ']

    # Check if the predicted value matches the actual value
    if predicted == actual:
        correct_count += 1
    else:
        wrong_count += 1
corrected_gb = correct_count
wrong_gb = wrong_count
# Print the counts
print("Correctly predicted count:", correct_count)
print("Wrongly predicted count:", wrong_count)

#  .................................. KNN
#  ....................... HOW ARE TRULY PREDICTED AND HOW ARE WRONGLY PREDICTED......................

# Read the Excel file
df = pd.read_excel('predicted_actual_knn.xlsx')

# Initialize counters
correct_count = 0
wrong_count = 0

# Iterate through the rows in the DataFrame
for index, row in df.iterrows():
    predicted = row['Predicted knn']
    actual = row['Actual ']

    # Check if the predicted value matches the actual value
    if predicted == actual:
        correct_count += 1
    else:
        wrong_count += 1
corrected_knn = correct_count
wrong_knn = wrong_count
# Print the counts
print("Correctly predicted count:", correct_count)
print("Wrongly predicted count:", wrong_count)

#  .................................. LOGISTIC REGRESSION
#  ....................... HOW ARE TRULY PREDICTED AND HOW ARE WRONGLY PREDICTED......................

# Read the Excel file
df = pd.read_excel('predicted_actual_lr.xlsx')

# Initialize counters
correct_count = 0
wrong_count = 0

# Iterate through the rows in the DataFrame
for index, row in df.iterrows():
    predicted = row['Predicted Lr']
    actual = row['Actual ']

    # Check if the predicted value matches the actual value
    if predicted == actual:
        correct_count += 1
    else:
        wrong_count += 1
corrected_lr = correct_count
wrong_lr = wrong_count
# Print the counts
print("Correctly predicted count:", correct_count)
print("Wrongly predicted count:", wrong_count)

#  ..................................NAIVE BEYES
#  ....................... HOW ARE TRULY PREDICTED AND HOW ARE WRONGLY PREDICTED......................

# Read the Excel file
df = pd.read_excel('predicted_actual_nb.xlsx')

# Initialize counters
correct_count = 0
wrong_count = 0

# Iterate through the rows in the DataFrame
for index, row in df.iterrows():
    predicted = row['Predicted nb']
    actual = row['Actual ']

    # Check if the predicted value matches the actual value
    if predicted == actual:
        correct_count += 1
    else:
        wrong_count += 1
corrected_nb = correct_count
wrong_nb = wrong_count
# Print the counts
print("Correctly predicted count:", correct_count)
print("Wrongly predicted count:", wrong_count)

#  .................................. RANDOM FOREST

#  ....................... HOW ARE TRULY PREDICTED AND HOW ARE WRONGLY PREDICTED......................

# Read the Excel file
df = pd.read_excel('predicted_actual_rf.xlsx')

# Initialize counters
correct_count = 0
wrong_count = 0

# Iterate through the rows in the DataFrame
for index, row in df.iterrows():
    predicted = row['Predicted rf']
    actual = row['Actual ']

    # Check if the predicted value matches the actual value
    if predicted == actual:
        correct_count += 1
    else:
        wrong_count += 1
corrected_rf = correct_count
wrong_rf = wrong_count
# Print the counts
print("Correctly predicted count:", correct_count)
print("Wrongly predicted count:", wrong_count)



"""## Visualizing the correct and wronlgy predicted"""

import matplotlib.pyplot as plt
import numpy as np

# Data
labels = ['Logistic Regression', 'Decision Tree', 'Gradient Boosting', 'KNN', 'Naive Bayes', 'Random Forest', 'SVM']
corrected_counts = [corrected_lr, corrected_dt, corrected_gb, corrected_knn, corrected_nb, corrected_rf, corrected_svm]
wrong_counts = [wrong_lr, wrong_dt, wrong_gb, wrong_knn, wrong_nb, wrong_rf, wrong_svm]


# Sort the algorithms based on corrected counts
sorted_indices = np.argsort(corrected_counts)[::-1]
sorted_labels = [labels[i] for i in sorted_indices]
sorted_corrected_counts = [corrected_counts[i] for i in sorted_indices]
sorted_wrong_counts = [wrong_counts[i] for i in sorted_indices]

# Define individual colors for each bar
corrected_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2']
wrong_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2']

# Create the figure and axes
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))

# Bar graph for correctly predicted counts
ax1.bar(range(len(sorted_labels)), sorted_corrected_counts, color=corrected_colors)
ax1.set_ylabel('Correctly Predicted Counts')
ax1.set_title('Correctly Predicted Counts by Algorithm')

# Set the x-axis tick labels as rankings
ax1.set_xticks(range(len(sorted_labels)))
ax1.set_xticklabels([f'{i+1}. {label}' for i, label in enumerate(sorted_labels)], rotation=45, ha='right')

# Add ranking number and count at the top of each bar
for i, count in enumerate(sorted_corrected_counts):
    ax1.text(i, count, f'{i+1}\n({count})', ha='center', va='bottom')

# Bar graph for wrongly predicted counts
ax2.bar(range(len(sorted_labels)), sorted_wrong_counts, color=wrong_colors)
ax2.set_ylabel('Wrongly Predicted Counts')
ax2.set_title('Wrongly Predicted Counts by Algorithm')

# Set the x-axis tick labels as rankings
ax2.set_xticks(range(len(sorted_labels)))
ax2.set_xticklabels([f'{i+1}. {label}' for i, label in enumerate(sorted_labels)], rotation=45, ha='right')

# Add ranking number and count at the top of each bar
for i, count in enumerate(sorted_wrong_counts):
    ax2.text(i, count, f'{i+1}\n({count})', ha='center', va='bottom')

# Adjust the y-axis limits to add more space at the top
ax1.set_ylim(top=max(sorted_corrected_counts) * 1.3)
ax2.set_ylim(top=max(sorted_wrong_counts) * 1.3)

# Adjust the layout
plt.tight_layout()

# Save the figure (optional)
plt.savefig('presentation_graph.png', dpi=300)

# Display the bar graphs
plt.show()















"""# Part 10: Importing and working with test dataset"""

test  = pd.read_csv("test.csv")

test.head()

test.columns

"""## Feature Engineering on Teset data"""

# Create new features
test['total_camera_megapixels'] = test['fc'] + test['pc']  # Total megapixels of front and primary cameras
test['screen_area'] = test['sc_h'] * test['sc_w']  # Screen area in square units
test['memory_to_weight_ratio'] = test['int_memory'] / test['mobile_wt']  # Memory to weight ratio
test['screen_resolution'] = test['px_width'] * test['px_height']  # Screen resolution in pixels
# data['screen_resolution'] = data['px_width'].astype(str) + 'x' + data['px_height'].astype(str)

test['processor_speed'] = test['clock_speed'] * test['n_cores']  # Processor speed based on clock speed and number of cores

# Assuming your dataset is stored in a pandas DataFrame called 'df'
test['ram'] = test['ram'] / 1024
test.rename(columns={'ram': 'ram_GB'}, inplace=True)

# Network Compatibility:
# "0" for no network compatibility,
# "1" for 3G compatibility,
# "2" for 4G compatibility, and
# "3" for devices compatible with both 3G and 4G networks.
test['network_compatibility'] = test['three_g'] + test['four_g'] * 2

# Delete used columns
test.drop(['fc', 'pc', 'sc_h', 'sc_w', 'px_height', 'px_width', 'clock_speed', 'int_memory', 'mobile_wt', 'n_cores','three_g', 'four_g'], axis=1, inplace=True)

test.head()

test.shape

"""## deleting undeed vairalbes"""

test = test.drop(['id'], axis = 1)

test.shape

# test.head()

"""## Scaling test data using StandardScaler"""

test = scaler.fit_transform(test)

test

"""# Part 11: Predicint unseen data

"""

data.shape, test.shape

test

fistrowoftest = [[1043	,1	,1,	0.1,	3.394531	,2	,1,	0,	30,	84,	0.025907	,319112,	5.4,	0]]
lr.predict(scaler.transform(fistrowoftest))

secondrowoftst = [[	841	,1	,1,	0.8	,3.803711,7	,0	,0	,16,	0,	0.319372,	639322,2.5,3	]]
lr.predict(scaler.transform(secondrowoftst))

thirdrowftest = [[1807,	1	,0	,0.9	,2.339844	,10	,1,	1,	5	,170,	0.145161	,1734820	,8.4	,0	]]
lr.predict(scaler.transform(thirdrowftest))

lr.predict(test)



testd.head()



